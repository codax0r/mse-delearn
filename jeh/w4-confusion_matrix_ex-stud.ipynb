{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hand-In of Group 13, Jonathan Ehrengruber (jonathan.ehrengruber@students.fhnw.ch), Christian Renold (christian.renold@hslu.ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Load first dataset  - Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>y_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.348450e-08</td>\n",
       "      <td>7.493480e-10</td>\n",
       "      <td>8.083470e-07</td>\n",
       "      <td>2.082290e-05</td>\n",
       "      <td>5.222360e-10</td>\n",
       "      <td>2.330260e-08</td>\n",
       "      <td>5.241270e-12</td>\n",
       "      <td>9.999650e-01</td>\n",
       "      <td>4.808590e-07</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.334270e-03</td>\n",
       "      <td>3.202960e-05</td>\n",
       "      <td>8.504280e-01</td>\n",
       "      <td>1.669090e-03</td>\n",
       "      <td>1.546460e-07</td>\n",
       "      <td>2.412940e-04</td>\n",
       "      <td>1.448280e-01</td>\n",
       "      <td>1.122810e-11</td>\n",
       "      <td>1.456330e-03</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.643050e-06</td>\n",
       "      <td>9.962760e-01</td>\n",
       "      <td>2.045910e-03</td>\n",
       "      <td>4.210530e-04</td>\n",
       "      <td>2.194020e-05</td>\n",
       "      <td>1.644130e-05</td>\n",
       "      <td>2.838160e-04</td>\n",
       "      <td>3.722960e-04</td>\n",
       "      <td>5.150120e-04</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9.998200e-01</td>\n",
       "      <td>2.550390e-10</td>\n",
       "      <td>1.112010e-05</td>\n",
       "      <td>1.653200e-05</td>\n",
       "      <td>5.375730e-10</td>\n",
       "      <td>8.999750e-05</td>\n",
       "      <td>9.380920e-06</td>\n",
       "      <td>4.464470e-05</td>\n",
       "      <td>2.418440e-06</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.092460e-08</td>\n",
       "      <td>7.464220e-08</td>\n",
       "      <td>3.560820e-05</td>\n",
       "      <td>5.496200e-07</td>\n",
       "      <td>9.988960e-01</td>\n",
       "      <td>3.070920e-08</td>\n",
       "      <td>2.346150e-04</td>\n",
       "      <td>9.748010e-07</td>\n",
       "      <td>1.071610e-06</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0             1             2             3             4  \\\n",
       "0  5.348450e-08  7.493480e-10  8.083470e-07  2.082290e-05  5.222360e-10   \n",
       "1  1.334270e-03  3.202960e-05  8.504280e-01  1.669090e-03  1.546460e-07   \n",
       "2  3.643050e-06  9.962760e-01  2.045910e-03  4.210530e-04  2.194020e-05   \n",
       "3  9.998200e-01  2.550390e-10  1.112010e-05  1.653200e-05  5.375730e-10   \n",
       "4  2.092460e-08  7.464220e-08  3.560820e-05  5.496200e-07  9.988960e-01   \n",
       "\n",
       "              5             6             7             8         9  y_true  \n",
       "0  2.330260e-08  5.241270e-12  9.999650e-01  4.808590e-07  0.000013       7  \n",
       "1  2.412940e-04  1.448280e-01  1.122810e-11  1.456330e-03  0.000011       2  \n",
       "2  1.644130e-05  2.838160e-04  3.722960e-04  5.150120e-04  0.000044       1  \n",
       "3  8.999750e-05  9.380920e-06  4.464470e-05  2.418440e-06  0.000006       0  \n",
       "4  3.070920e-08  2.346150e-04  9.748010e-07  1.071610e-06  0.000831       4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Note: Adjust data path if needed\n",
    "datapath = '../data/ex1-system-a.csv'\n",
    "datasetA = pd.read_csv(datapath,names=['0','1','2','3','4','5','6','7','8','9','y_true','unused'], sep = \";\")\n",
    "datasetA = datasetA.drop('unused', axis = 1) #Â drop the last colomn without any information in it.\n",
    "classes_name = ['0','1','2','3','4','5','6','7','8','9']\n",
    "nb_classes = 10\n",
    "datasetA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = datasetA['y_true'].values\n",
    "y_scores_A = datasetA[classes_name].values   #isolate the matrix of scores\n",
    "y_pred_A = np.argmax(y_scores_A,axis=1)      #elect winner class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) What is the overall error rate of the system ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall error rate of the system :  0.10729999999999995\n"
     ]
    }
   ],
   "source": [
    "### START YOUR CODE\n",
    "overall_rate = 1 - (y_true == y_pred_A).sum() / y_true.shape[0]\n",
    "### END YOUR CODE\n",
    "\n",
    "print('overall error rate of the system : ',overall_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Compute and report the confusion matrix of the system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a second one our selfs and ckeck if it is correct with the \"correct\" one from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tp(y_true, y_pred, label):\n",
    "    indices = np.argwhere(y_true == label)\n",
    "    tp = (y_pred[indices] == label).sum()\n",
    "    return tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fp(y_true, y_pred, label):\n",
    "    indices = np.argwhere(y_true != label)\n",
    "    fp = (y_pred[indices] == label).sum()\n",
    "    return fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tn(y_true, y_pred, label, antilabel):\n",
    "    indices = np.argwhere(y_true != label)\n",
    "    tn = (y_pred[indices] != label).sum()\n",
    "    return tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn(y_true, y_pred, label):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tn() missing 1 required positional argument: 'antilabel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-923e78b3b1c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: tn() missing 1 required positional argument: 'antilabel'"
     ]
    }
   ],
   "source": [
    "tn(y_true, y_pred_A, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1112"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp(y_true, y_pred_A, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp(y_true, y_pred_A, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix2(y_true,y_pred,nb_classes):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    y_true -- groud truth labels\n",
    "    y_pred -- predicted values\n",
    "    n_classes -- number of classes\n",
    "    \n",
    "    Returns:\n",
    "    the confusion matrix as 2d numpy array \n",
    "    \"\"\"\n",
    "    ### START YOUR CODE\n",
    "    counts = np.zeros((nb_classes, nb_classes))\n",
    "    for i in range(nb_classes):\n",
    "        for j in range(nb_classes):\n",
    "            counts[i, j] = (y_true[y_true == i] == y_pred[y_pred == j]).sum()\n",
    "    ### END YOUR CODE\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'bool' object has no attribute 'sum'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-47d26b355a43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mverif_cm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred_A\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcm_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_A\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnb_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# verification for our confusion matrix function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm_A\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mverif_cm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnb_classes\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-9671f8361479>\u001b[0m in \u001b[0;36mconfusion_matrix2\u001b[0;34m(y_true, y_pred, nb_classes)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mcounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m### END YOUR CODE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'bool' object has no attribute 'sum'"
     ]
    }
   ],
   "source": [
    "# TEST - we use the sklearn builit in functionality\n",
    "from sklearn.metrics import confusion_matrix\n",
    "verif_cm = confusion_matrix(y_true,y_pred_A)\n",
    "\n",
    "cm_A = confusion_matrix2(y_true, y_pred_A,nb_classes)\n",
    "# verification for our confusion matrix function\n",
    "print((cm_A == verif_cm).sum() == nb_classes**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to plot the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plot_confusion_matrix(cm_A, classes=classes_name,title='Confusion matrix for System A, without normalization')\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm_A, classes=classes_name, normalize=True,\n",
    "                      title='Normalized confusion matrix for System B')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â d) What are the worst and best classes in terms of precision and sensitivity (recall) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_per_class(cm):\n",
    "    \"\"\"\n",
    "    Aguments:\n",
    "    cm -- confusion matrix\n",
    "    Returns:\n",
    "    Precision per class, i.e. a numpy array of length given by the number of classes\n",
    "    \"\"\"\n",
    "    ### START YOUR CODE  \n",
    "    \n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_per_class(cm):\n",
    "    \"\"\"\n",
    "    Aguments:\n",
    "    cm -- confusion matrix\n",
    "    Returns:\n",
    "    Recall per class, i.e. a numpy array of length given by the number of classes\n",
    "    \"\"\"\n",
    "    ### START YOUR CODE  \n",
    "\n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions = precision_per_class(cm_A)\n",
    "# should return '1' as best (95.7%)\n",
    "# and '5' as worst (81.4%) \n",
    "\n",
    "best_class = np.argmax(precisions)\n",
    "worst_class = np.argmin(precisions)\n",
    "print('best precision class  : ', best_class, '[', precisions[best_class],']')\n",
    "print('worst precision class : ', worst_class, '[', precisions[worst_class],']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls = recall_per_class(cm_A)\n",
    "# should return '1' as best (97.97%)\n",
    "# and '8' as worst (79.26%) \n",
    "\n",
    "best_class = np.argmax(recalls)\n",
    "worst_class = np.argmin(recalls)\n",
    "print('best recall class  : ', best_class, '[',recalls[best_class],']')\n",
    "print('worst recall class : ', worst_class, '[',recalls[worst_class],']')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Load second dataset  - Scores\n",
    "\n",
    "Find the output of a second system B. It contains the same ground truth values - but different predictions.\n",
    "What is the best system between (a) and (b) in terms of error rate and F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetB = pd.read_csv('ex1-system-b.csv',names=['0','1','2','3','4','5','6','7','8','9','y_true','unused'], sep = \";\")\n",
    "datasetB = datasetB.drop('unused', axis = 1) #Â drop the last colomn without any information in it.\n",
    "datasetB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = datasetB['y_true'].values\n",
    "y_scores_B = datasetB[classes_name].values   #isolate the matrix of scores\n",
    "y_pred_B = np.argmax(y_scores_B,axis=1)      #elect winner class\n",
    "\n",
    "cm_B = confusion_matrix2(y_true,y_pred_B,nb_classes)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm_B, classes=classes_name,title='Confusion matrix for System B, without normalization')\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm_B, classes=classes_name, normalize=True,\n",
    "                      title='Normalized confusion matrix for System B')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def system_precision(cm):\n",
    "    ### START YOUR CODE\n",
    "\n",
    "    ### END YOUR CODE\n",
    "\n",
    "def system_recall(cm):\n",
    "    ### START YOUR CODE\n",
    "\n",
    "    ### END YOUR CODE\n",
    "    \n",
    "def system_accuracy(cm):\n",
    "    ### START YOUR CODE\n",
    "\n",
    "    ### END YOUR CODE\n",
    "    \n",
    "def system_f1_score(cm):\n",
    "    ### START YOUR CODE\n",
    "\n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('System A\\n\\trecall : ',system_recall(cm_A),'\\n\\tprecision : ',system_precision(cm_A),'\\n\\taccuracy : ',system_accuracy(cm_A),'\\n\\tf1-score : ',f1_score(cm_A))\n",
    "print('System B\\n\\trecall : ',system_recall(cm_B),'\\n\\tprecision : ',system_precision(cm_B),'\\n\\taccuracy : ',system_accuracy(cm_B),'\\n\\tf1-score : ',f1_score(cm_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: check with the recall_score and precision_score function of SciKit Learn ```from sklearn.metrics import recall_score, precision_score``` that you obtain correct recall and precision values (use the argument ```average=\"macro\"```)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
